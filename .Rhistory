theme_bw() +
theme(legend.text = element_text(size = 16),
legend.title = element_text(size = 16),
axis.text.x = element_text(size = 12,angle = 270,hjust = 0,vjust = .5),
axis.text.y = element_text(size = 12),
axis.title = element_text(size = 14)) +
theme(aspect.ratio = 1)
lm_poly = lm(Density ~ Core +  poly(Depth,4),data = snow)
AIC(lm_poly)
lm_poly_int = lm(Density ~ Core *  poly(Depth,4),data = snow)
AIC(lm_poly_int)
lm_poly_int = lm(Density ~ Core *  poly(Depth,3),data = snow)
lm_poly = lm(Density ~ Core +  poly(Depth,3),data = snow)
lm_spline_linear = lm(Density ~ Core +
bs(Depth,knots = quantile(Depth,c(10)), degree = 3),
data = snow)
lm_spline_linear = lm(Density ~ Core +
bs(Depth,knots = 10, degree = 3),
data = snow)
lm_spline_cub = lm(Density ~ Core +
bs(Depth,knots = 10, degree = 3),
data = snow)
AIC(lm_spline_cub)
lm_spline_cub_int = lm(Density ~ Core *
bs(Depth,knots = 10, degree = 3),
data = snow)
lm_spline_cub_int = lm(Density ~ Core *
bs(Depth,knots = 10, degree = 3),
data = snow)
snow$pred.spline = predict(lm_spline_cub_int)
snow$resid.spline = lm_spline_cub_int$residuals
AIC(lm_spline_cub_int)
lm_snow = lm(Density ~ Depth * Core ,data = snow)
snow$pred.linear = predict(lm_snow)
snow$resid.linear = resid(lm_snow)
site1 <- subset(snow, Core == 1)
ggplot(site1, aes(x = Depth, y = Density)) + geom_point() +
geom_line(aes(x = Depth, y = pred.linear, group = Core, col = Core), size =1.5) +
theme_bw() +
theme(legend.text = element_text(size = 16),
legend.title = element_text(size = 16),
axis.text.x = element_text(size = 12,angle = 270,hjust = 0,vjust = .5),
axis.text.y = element_text(size = 12),
axis.title = element_text(size = 14)) +
theme(aspect.ratio = 1)
ggplot(site1, aes(x = Depth, y = Density)) + geom_point() +
geom_line(aes(x = Depth, y = pred.spline, group = Core, col = Core), size =1.5) +
theme_bw() +
theme(legend.text = element_text(size = 16),
legend.title = element_text(size = 16),
axis.text.x = element_text(size = 12,angle = 270,hjust = 0,vjust = .5),
axis.text.y = element_text(size = 12),
axis.title = element_text(size = 14)) +
theme(aspect.ratio = 1)
ggplot(site1, aes(x = Depth, y = resid.spline)) + geom_point() +
geom_smooth() +
theme_bw() +
theme(legend.text = element_text(size = 16),
legend.title = element_text(size = 16),
axis.text.x = element_text(size = 12,angle = 270,hjust = 0,vjust = .5),
axis.text.y = element_text(size = 12),
axis.title = element_text(size = 14)) +
theme(aspect.ratio = 1)
ggplot(site1, aes(x = Depth, y = Density)) + geom_point() +
geom_line(aes(x = Depth, y = pred.spline, group = Core, col = Core), size =1.5) +
geom_smooth() +
theme_bw() +
theme(legend.text = element_text(size = 16),
legend.title = element_text(size = 16),
axis.text.x = element_text(size = 12,angle = 270,hjust = 0,vjust = .5),
axis.text.y = element_text(size = 12),
axis.title = element_text(size = 14)) +
theme(aspect.ratio = 1)
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(splines)
snow = read_csv("snow_core.csv")
head(snow)
lm_prelim = lm(Density ~ Depth + Core ,data = snow)
summary(lm_prelim)
AIC(lm_prelim)
lm_snow = lm(Density ~ Depth * Core ,data = snow)
snow$pred.linear = predict(lm_snow)
snow$resid.linear = resid(lm_snow)
AIC(lm_snow)
site1 <- subset(snow, Core == 1)
ggplot(site1, aes(x = Depth, y = Density)) + geom_point() +
geom_line(aes(x = Depth, y = pred.linear, group = Core, col = Core), size =1.5) +
theme_bw() +
theme(legend.text = element_text(size = 16),
legend.title = element_text(size = 16),
axis.text.x = element_text(size = 12,angle = 270,hjust = 0,vjust = .5),
axis.text.y = element_text(size = 12),
axis.title = element_text(size = 14)) +
theme(aspect.ratio = 1)
ggplot(site1, aes(x = Depth, y = resid.linear)) + geom_point() +
geom_smooth() +
theme_bw() +
theme(legend.text = element_text(size = 16),
legend.title = element_text(size = 16),
axis.text.x = element_text(size = 12,angle = 270,hjust = 0,vjust = .5),
axis.text.y = element_text(size = 12),
axis.title = element_text(size = 14)) +
theme(aspect.ratio = 1)
lm_poly = lm(Density ~ Core +  poly(Depth,3),data = snow)
AIC(lm_poly)
lm_poly_int = lm(Density ~ Core *  poly(Depth,3),data = snow)
AIC(lm_poly_int)
lm_spline_cub = lm(Density ~ Core +
bs(Depth,knots = 10, degree = 3),
data = snow)
AIC(lm_spline_cub)
lm_spline_cub_int = lm(Density ~ Core *
bs(Depth,knots = 10, degree = 3),
data = snow)
snow$pred.spline = predict(lm_spline_cub_int)
snow$resid.spline = lm_spline_cub_int$residuals
AIC(lm_spline_cub_int)
ggplot(site1, aes(x = Depth, y = Density)) + geom_point() +
geom_line(aes(x = Depth, y = pred.spline, group = Core, col = Core), size =1.5) +
geom_smooth() +
theme_bw() +
theme(legend.text = element_text(size = 16),
legend.title = element_text(size = 16),
axis.text.x = element_text(size = 12,angle = 270,hjust = 0,vjust = .5),
axis.text.y = element_text(size = 12),
axis.title = element_text(size = 14)) +
theme(aspect.ratio = 1)
ggplot(site1, aes(x = Depth, y = Density)) + geom_point() +
geom_line(aes(x = Depth, y = pred.spline, group = Core, col = Core), size =1.5) +
geom_smooth() +
theme_bw() +
theme(legend.text = element_text(size = 16),
legend.title = element_text(size = 16),
axis.text.x = element_text(size = 12,angle = 270,hjust = 0,vjust = .5),
axis.text.y = element_text(size = 12),
axis.title = element_text(size = 14)) +
theme(aspect.ratio = 1)
lm_spline_cub_int = lm(Density ~ Core *
bs(Depth,knots = 10, degree = 3),
data = snow)
snow$pred.spline = predict(lm_spline_cub_int)
snow$resid.spline = lm_spline_cub_int$residuals
ggplot(site1, aes(x = Depth, y = Density)) + geom_point() +
geom_line(aes(x = Depth, y = pred.spline, group = Core, col = Core), size =1.5) +
geom_smooth() +
theme_bw() +
theme(legend.text = element_text(size = 16),
legend.title = element_text(size = 16),
axis.text.x = element_text(size = 12,angle = 270,hjust = 0,vjust = .5),
axis.text.y = element_text(size = 12),
axis.title = element_text(size = 14)) +
theme(aspect.ratio = 1)
site1 <- subset(snow, Core == 1)
site1 <- subset(snow, Core == 1)
ggplot(site1, aes(x = Depth, y = Density)) + geom_point() +
geom_line(aes(x = Depth, y = pred.spline, group = Core, col = Core), size =1.5) +
geom_smooth() +
theme_bw() +
theme(legend.text = element_text(size = 16),
legend.title = element_text(size = 16),
axis.text.x = element_text(size = 12,angle = 270,hjust = 0,vjust = .5),
axis.text.y = element_text(size = 12),
axis.title = element_text(size = 14)) +
theme(aspect.ratio = 1)
ggplot(site1, aes(x = Depth, y = resid.spline)) + geom_point() +
geom_smooth() +
theme_bw() +
theme(legend.text = element_text(size = 16),
legend.title = element_text(size = 16),
axis.text.x = element_text(size = 12,angle = 270,hjust = 0,vjust = .5),
axis.text.y = element_text(size = 12),
axis.title = element_text(size = 14)) +
theme(aspect.ratio = 1)
site1 <- subset(snow, Core == 1)
ggplot(site1, aes(x = Depth, y = Density)) + geom_point() +
geom_line(aes(x = Depth, y = pred.linear, group = Core, col = Core), size =1.5) +
theme_bw() +
theme(legend.text = element_text(size = 16),
legend.title = element_text(size = 16),
axis.title = element_text(size = 14)) +
theme(aspect.ratio = 1)
site1 <- subset(snow, Core == 1)
ggplot(site1, aes(x = Depth, y = Density)) + geom_point() +
theme_bw() +
geom_line(aes(x = Depth, y = pred.linear, group = Core, col = Core), size =1.5) +
theme(legend.text = element_text(size = 16),
legend.title = element_text(size = 16),
axis.title = element_text(size = 14)) +
theme(aspect.ratio = 1)
site1 <- subset(snow, Core == 1)
ggplot(site1, aes(x = Depth, y = Density)) + geom_point() +
theme_bw() +
geom_line(aes(x = Depth, y = pred.linear, group = Core, col = Core), size =1.5) +
theme(legend.text = element_text(size = 16),
legend.title = element_text(size = 16),
axis.title = element_text(size = 14)) +
theme(aspect.ratio = 1)
site1 <- subset(snow, Core == 1)
ggplot(site1, aes(x = Depth, y = Density)) +
geom_point() +
theme_bw() +
geom_line(aes(x = Depth, y = pred.linear, group = Core, col = Core), size =1.5) +
theme(legend.text = element_text(size = 16),
legend.title = element_text(size = 16),
axis.title = element_text(size = 14)) +
theme(aspect.ratio = 1)
library(tidyverse)
library(corrplot)  # for the correlation matrix
library(bestglm)  # for variable selection
library(car)  # for VIFs
library(MASS)  # for negative binomial regression
library(pscl)  # for zero-inflated regression
library(gridExtra)
bikes <- read_csv("Bikes.csv") %>%
mutate_if(is.character, as.factor)
bikes$yr <- as.factor(bikes$yr)
summary(bikes)
ggplot(data = bikes) +
geom_histogram(mapping = aes(x = cnt, y = ..density..),
binwidth = 100) +
theme_bw() +
theme(aspect.ratio = 1)
bikes_model <- bestglm(as.data.frame(bikes),
IC = "BIC",
method = "exhaustive",
TopModels = 1,
family = poisson)
summary(bikes_model$BestModel)
bikes_poisson <- glm(cnt ~ season + yr + holiday +
workingday + weathersit + temp + hum + windspeed,
data = bikes,
family = poisson(link = "log"))
summary(bikes_poisson)
#Temperature
ggplot(data = bikes, mapping = aes(y = log(cnt + 1), x = temp)) +
geom_point() +
theme_bw() +
theme(aspect.ratio = 1)
#Humidity
ggplot(data = bikes, mapping = aes(y = log(cnt + 1), x = hum)) +
geom_point() +
theme_bw() +
theme(aspect.ratio = 1)
#Windspeed
ggplot(data = bikes, mapping = aes(y = log(cnt + 1), x = windspeed)) +
geom_point() +
theme_bw() +
theme(aspect.ratio = 1)
# Use added variable plots for any continuous predictors you included in the
# model
avPlots(bikes_poisson, terms = ~ temp + hum + windspeed)
bikes.cooks <- data.frame("cooks.distance" = cooks.distance(bikes_poisson))
bikes.cooks$obs <- 1:nrow(bikes)
ggplot(data = bikes.cooks) +
geom_point(mapping = aes(x = obs, y = abs(cooks.distance))) +
geom_hline(mapping = aes(yintercept = 4/ length(obs)),
color = "red", linetype = "dashed") +  # for n > 30
geom_hline(mapping = aes(yintercept = 1),
color = "red", linetype = "dashed") +  # for n > 30
theme_bw() +
theme(aspect.ratio = 1)
bikes$cooksd <- cooks.distance(bikes_poisson)
bikes %>%
mutate(rowNum = row.names(bikes)) %>%  # save original row numbers
filter(cooksd > 4 / length(cooksd)) %>%  # select potential outliers
arrange(desc(cooksd))
library(tidyverse)
library(ggfortify)  # plot lm objects using ggplot instead of base R
library(car)  # needed for added-variable plots and dfbetas
library(corrplot)  # colored correlation matrix
# install.packages("devtools")
# devtools::install_github("thomasp85/patchwork")
library(patchwork)
FatComplete <- read_table("BodyFat.txt")
bodyfat<- FatComplete %>%
select(-row)
summary(bodyfat)
pairs(bodyfat, pch = 19)
round(cor(bodyfat), 2)
corrplot(cor(bodyfat), type = "upper")
bodyfat_lm <- lm(brozek ~ ., data = bodyfat)
summary(bodyfat_lm)
bodyfat$residuals <- bodyfat_lm$residuals
bodyfat_resid_vs_fit <- autoplot(bodyfat_lm, which = 1, ncol = 1, nrow = 1) +
theme(aspect.ratio = 1)
bodyfat_resid_vs_fit
plot4
## Loading Libraries
library(tidyverse)
library(vroom)
library(DataExplorer)
library(patchwork)
# Load data
bike <- vroom('./train.csv')
## Set up grid of tuning values
tuning_grid <- grid_regular(mtry(range = c(1,ncol(bike_cleaned)-1)), # The range has to be the number of variables we will use to predict
min_n(),
levels = 3)
## Loading Libraries
library(tidyverse)
library(vroom)
library(tidymodels)
# Load data
bike <- vroom('./train.csv')
setwd('~/College/Stat348/KaggleBikeShare')
# Load data
bike <- vroom('./train.csv')
bike_test <- vroom('./test.csv')
# Clean data
bike_cleaned <- bike %>%
select(-'registered', -'casual') %>%
mutate(lg_count = log(count)) %>% #Create the log variable of count
select(-count)
# Feature Engineering
my_recipe <- recipe(lg_count~., data=bike_cleaned) %>% # Set model formula and data
step_mutate(weather = ifelse(weather == 4, 3, weather)) %>% # where weather is 4 change to 3 (only one value like that)
step_date(datetime, features="dow") %>% # gets day of week
step_time(datetime, features="hour") %>% # gets hour
step_dummy(all_nominal_predictors()) %>% #create dummy variables
step_normalize(all_numeric_predictors()) %>% # Make mean 0, sd=1
step_rm('workingday', 'datetime')
library(tidymodels)
library(rpart)
rf_mod <- rand_forest(mtry = tune(),
min_n=tune(),
trees=500) %>% #Type of model
set_engine("ranger") %>% # What R function to use
set_mode("regression")
my_recipe <- recipe(lg_count~., data=bike_cleaned) %>% # Set model formula and data
step_mutate(weather = ifelse(weather == 4, 3, weather)) %>% # where weather is 4 change to 3 (only one value like that)
step_date(datetime, features="dow") %>% # gets day of week
step_time(datetime, features="hour") %>% # gets hour
step_rm('workingday', 'datetime')
rf_wf <- workflow() %>% # map of what to do to replicate code with new data/test data
add_recipe(my_recipe) %>%
add_model(rf_mod)
## Set up grid of tuning values
tuning_grid <- grid_regular(mtry(range = c(1,ncol(bike_cleaned)-1)), # The range has to be the number of variables we will use to predict
min_n(),
levels = 3)
## Set up K-fold CV
folds <- vfold_cv(bike_cleaned, v = 5, repeats=1)
CV_results <- rf_wf %>%
tune_grid(resamples=folds,
grid=tuning_grid,
metrics=metric_set(rmse, mae))
## Find best tuning parameters
bestTune <- CV_results %>%
select_best("rmse")
final_wf <- rf_wf %>%
finalize_workflow(bestTune) %>%
fit(data=bike_cleaned)
bike_pred_rf <- final_wf %>%
predict(new_data = bike_test)
# clean format
predictions <- bike_pred_rf %>%
mutate(datetime = bike_test$datetime) %>%
mutate(count = exp(.pred)) %>% # exponentiate lg_count
select(datetime, count)
predictions$datetime <- as.character(format(predictions$datetime))
vroom_write(predictions, 'BikeSharePreds.csv', delim = ",")
library(stacks)
install.packages('stacks')
library(stacks)
## Loading Libraries
library(tidyverse)
library(vroom)
library(tidymodels)
# Load data
bike <- vroom('./train.csv')
bike_test <- vroom('./test.csv')
# Clean data
bike_cleaned <- bike %>%
select(-'registered', -'casual') %>%
mutate(lg_count = log(count)) %>% #Create the log variable of count
select(-count)
# Feature Engineering
my_recipe <- recipe(lg_count~., data=bike_cleaned) %>% # Set model formula and data
step_mutate(weather = ifelse(weather == 4, 3, weather)) %>% # where weather is 4 change to 3 (only one value like that)
step_date(datetime, features="dow") %>% # gets day of week
step_time(datetime, features="hour") %>% # gets hour
step_dummy(all_nominal_predictors()) %>% #create dummy variables
step_normalize(all_numeric_predictors()) %>% # Make mean 0, sd=1
step_rm('workingday', 'datetime')
## Control Settings for Stacking models
untunedModel <- control_stack_grid()
tunedModel <- control_stack_resamples()
## Split data for CV
folds <- vfold_cv(trainDataSet, v = 3, repeats=1)
## Split data for CV
folds <- vfold_cv(bike_cleaned, v = 3, repeats=1)
## Control Settings for Stacking models
untunedModel <- control_stack_grid()
tunedModel <- control_stack_resamples()
## Penalized Regression ##
preg_model <- linear_reg(penalty=tune(),
mixture=tune()) %>% #Set model and tuning
set_engine("glmnet") # Function to fit in R
## Set Workflow
preg_wf <- workflow() %>%
add_recipe(my_recipe) %>%
add_model(preg_model)
## Grid of values to tune over
tuning_grid <- grid_regular(penalty(),
mixture(),
levels = 5) ## L^2 total tuning possibilities
## Split data for CV
folds <- vfold_cv(bike_cleaned, v = 5, repeats=1)
## Run the CV
preg_models <- preg_wf %>%
tune_grid(resamples=folds,
grid=tuning_grid,
metrics=metric_set(rmse, mae),
control=untunedModel)
### Random Forest
rf_mod <- rand_forest(mtry = tune(),
min_n=tune(),
trees=250) %>% #Type of model
set_engine("ranger") %>% # What R function to use
set_mode("regression")
rf_wf <- workflow() %>% # map of what to do to replicate code with new data/test data
add_recipe(my_recipe) %>%
add_model(rf_mod)
## Set up grid of tuning values
tuning_grid <- grid_regular(mtry(range = c(1,ncol(bike_cleaned)-1)), # How many Variables to choose from
# researches have found log of total variables is enough
min_n(), # Number of observations in a leaf
levels = 3)
## Set up K-fold CV (This usually takes sometime)
folds <- vfold_cv(bike_cleaned, v = 5, repeats=1)
rf_models <- rf_wf %>%
tune_grid(resamples=folds,
grid=tuning_grid,
metrics=metric_set(rmse, mae),
control = untunedModel)
## Specify with models to include
bike_stack <- stacks() %>%
add_candidates(preg_models) %>%
add_candidates(rf_models)
# Fit the stacked model
fitted_bike_stack <-  bike_stack %>%
blend_predictions() %>%
fit_members()
## Specify with models to include
bike_stack <- stacks() %>%
add_candidates(preg_models) %>%
add_candidates(rf_models)
# Fit the stacked model
fitted_bike_stack <-  bike_stack %>%
blend_predictions() %>%
fit_members()
rf_models
## Split data for CV
folds <- vfold_cv(bike_cleaned, v = 3, repeats=1)
## Control Settings for Stacking models
untunedModel <- control_stack_grid()
tunedModel <- control_stack_resamples()
## Penalized Regression ##
preg_model <- linear_reg(penalty=tune(),
mixture=tune()) %>% #Set model and tuning
set_engine("glmnet") # Function to fit in R
## Set Workflow
preg_wf <- workflow() %>%
add_recipe(my_recipe) %>%
add_model(preg_model)
## Grid of values to tune over
tuning_grid <- grid_regular(penalty(),
mixture(),
levels = 5) ## L^2 total tuning possibilities
## Run the CV
preg_models <- preg_wf %>%
tune_grid(resamples=folds,
grid=tuning_grid,
metrics=metric_set(rmse, mae),
control=untunedModel)
### Random Forest
rf_mod <- rand_forest(mtry = tune(),
min_n=tune(),
trees=250) %>% #Type of model
set_engine("ranger") %>% # What R function to use
set_mode("regression")
rf_wf <- workflow() %>% # map of what to do to replicate code with new data/test data
add_recipe(my_recipe) %>%
add_model(rf_mod)
## Set up grid of tuning values
tuning_grid <- grid_regular(mtry(range = c(1,ncol(bike_cleaned)-1)), # How many Variables to choose from
# researches have found log of total variables is enough
min_n(), # Number of observations in a leaf
levels = 3)
rf_models <- rf_wf %>%
tune_grid(resamples=folds,
grid=tuning_grid,
metrics=metric_set(rmse, mae),
control = untunedModel)
bike_stack <- stacks() %>%
add_candidates(preg_models) %>%
add_candidates(rf_models)
# Fit the stacked model
fitted_bike_stack <-  bike_stack %>%
blend_predictions() %>%
fit_members()
#Predict
bike_pred_stack <- fitted_bike_stack %>%
predict(new_data = bike_test)
# clean format
predictions <- bike_pred_stack %>%
mutate(datetime = bike_test$datetime) %>%
mutate(count = exp(.pred)) %>% # exponentiate lg_count
select(datetime, count)
predictions$datetime <- as.character(format(predictions$datetime))
vroom_write(predictions, 'BikeSharePreds.csv', delim = ",")
